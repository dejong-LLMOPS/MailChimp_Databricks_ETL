{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1203531-c2eb-4ae0-95a3-ae55c2437727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Data Processing Pipeline for Mailchimp Data\n",
    "\n",
    "This script loads and unions multiple Delta files from a specified silver storage container,\n",
    "transforms the data, and writes three Delta tables to a gold storage container.\n",
    "\n",
    "The main steps include:\n",
    "- Loading all Delta files from the silver container and appending the list name as a new column.\n",
    "- Creating a contact dimension table (`dim_contact`) based on unique email IDs.\n",
    "- Creating a list dimension table (`dim_list`) based on list IDs.\n",
    "- Creating a fact table for list membership (`fact_list_membership`) with additional membership data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc359f96-a06a-437d-a1a0-737841274fea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules and functions from PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create or get an existing SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Define storage account and container information\n",
    "STORAGE_ACCOUNT_NAME = \"mailchimpspnetwork\"\n",
    "GOLD_CONTAINER = \"gold\"\n",
    "SILVER_CONTAINER = \"silver\"\n",
    "INPUT_PREFIX = \"mailchimp_transformed\"\n",
    "\n",
    "# Build the base paths for the gold and silver layers\n",
    "GOLD_BASE = f\"abfss://{GOLD_CONTAINER}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net\"\n",
    "SILVER_BASE = f\"abfss://{SILVER_CONTAINER}@{STORAGE_ACCOUNT_NAME}.dfs.core.windows.net/{INPUT_PREFIX}\"\n",
    "\n",
    "# -------------------------------------------\n",
    "# Load and union all delta files from the silver layer\n",
    "# -------------------------------------------\n",
    "\n",
    "# List all files and directories in the silver base path\n",
    "df_paths = dbutils.fs.ls(SILVER_BASE)\n",
    "# Filter the paths to only include directories (each directory represents a delta table for a list)\n",
    "delta_paths = [f.path for f in df_paths if f.isDir()]\n",
    "\n",
    "# Initialize a variable to hold the union of all data\n",
    "all_data = None\n",
    "\n",
    "# Loop through each delta file directory\n",
    "for path in delta_paths:\n",
    "    # Load the delta table from the current directory\n",
    "    df = spark.read.format(\"delta\").load(path)\n",
    "    # Add a column to identify the source list name using the directory name\n",
    "    df = df.withColumn(\"list_name_source\", lit(path.split(\"/\")[-1]))\n",
    "    # Union the current DataFrame with the accumulated DataFrame\n",
    "    all_data = df if all_data is None else all_data.unionByName(df)\n",
    "\n",
    "# Log the total record count and number of lists processed\n",
    "print(f\"Loaded {all_data.count()} records from {len(delta_paths)} lists\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 1. Create the dimension table 'dim_contact' based on unique_email_id\n",
    "# -------------------------------------------\n",
    "# Select required columns and remove duplicate records based on 'unique_email_id'\n",
    "dim_contact = all_data.select(\n",
    "    \"unique_email_id\",\n",
    "    \"email_address\",\n",
    "    \"full_name\",\n",
    "    \"merge_FNAME\",\n",
    "    \"merge_LNAME\",\n",
    "    \"merge_PHONE\",\n",
    "    \"address_addr1\",\n",
    "    \"address_addr2\",\n",
    "    \"address_city\",\n",
    "    \"address_state\",\n",
    "    \"address_zip\",\n",
    "    \"address_country\",\n",
    "    \"language\",\n",
    "    \"vip\"\n",
    ").dropDuplicates([\"unique_email_id\"])\n",
    "\n",
    "# Write the dimension table to the gold layer using Delta format and overwrite mode\n",
    "dim_contact.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/dim_contact\")\n",
    "print(\"dim_contact written to gold\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 2. Create the dimension table 'dim_list'\n",
    "# -------------------------------------------\n",
    "# Select required columns and remove duplicate records based on 'list_id'\n",
    "dim_list = all_data.select(\n",
    "    \"list_id\",\n",
    "    \"list_name\",\n",
    "    \"location_country_code\",\n",
    "    \"location_region\",\n",
    "    \"location_timezone\"\n",
    ").dropDuplicates([\"list_id\"])\n",
    "\n",
    "# Write the dimension table to the gold layer using Delta format and overwrite mode\n",
    "dim_list.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/dim_list\")\n",
    "print(\"dim_list written to gold\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# 3. Create the fact table 'fact_list_membership'\n",
    "# -------------------------------------------\n",
    "# Select required columns and remove duplicate records based on the combination of 'unique_email_id' and 'list_id'\n",
    "fact_membership = all_data.select(\n",
    "    \"unique_email_id\",\n",
    "    \"list_id\",\n",
    "    \"status\",\n",
    "    \"stats_avg_open_rate\",\n",
    "    \"stats_avg_click_rate\",\n",
    "    \"timestamp_signup\",\n",
    "    \"timestamp_opt\",\n",
    "    \"last_changed\",\n",
    "    \"member_rating\",\n",
    "    \"consents_to_one_to_one_messaging\",\n",
    "    \"email_client\",\n",
    "    \"email_type\",\n",
    "    \"web_id\"\n",
    ").dropDuplicates([\"unique_email_id\", \"list_id\"])\n",
    "\n",
    "# Write the fact table to the gold layer using Delta format and overwrite mode\n",
    "fact_membership.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/fact_list_membership\")\n",
    "print(\"fact_list_membership written to gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717d4afe-7cb2-4119-a0d5-ef472cd03c1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_GoldMaster",
   "widgets": {
    "sf_extra_cols": {
     "currentValue": "npo02__Total_Household_Gifts__c ",
     "nuid": "658c8790-f55c-4d11-bbc2-05a69b58291c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Id",
      "label": "Extra SF columns (comma-separated)",
      "name": "sf_extra_cols",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Id",
      "label": "Extra SF columns (comma-separated)",
      "name": "sf_extra_cols",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
