{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f55aff1-4ef0-48ba-9356-b9095a629396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#%run ./Mailchimp_ETL/Production_ETL/04_GoldMaster\n",
    "# Note: All functions and globals are assumed to be defined in __main__ after the %run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca57912a-18b8-449e-a6a4-cb5fecc4714b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch, MagicMock\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Create or get an existing SparkSession for testing\n",
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"GoldETLTest\").getOrCreate()\n",
    "\n",
    "# Create a fake dbutils.fs.ls response object\n",
    "class FakeFileInfo:\n",
    "    def __init__(self, path, isDir):\n",
    "        self.path = path\n",
    "        self.isDir = isDir\n",
    "\n",
    "# Create a fake dbutils object to simulate Databricks file listing\n",
    "class FakeDBUtils:\n",
    "    class FS:\n",
    "        def ls(self, path):\n",
    "            # Simulate two directories under the silver base\n",
    "            return [\n",
    "                FakeFileInfo(f\"{path}/delta1\", True),\n",
    "                FakeFileInfo(f\"{path}/delta2\", True)\n",
    "            ]\n",
    "    fs = FS()\n",
    "\n",
    "# Inject the fake dbutils into globals (as would exist in a Databricks notebook)\n",
    "dbutils = FakeDBUtils()\n",
    "\n",
    "# Sample data mimicking records from silver (each record contains all required columns)\n",
    "sample_data = [\n",
    "    {\n",
    "        \"unique_email_id\": \"uid_1\",\n",
    "        \"email_address\": \"john.doe@example.com\",\n",
    "        \"full_name\": \"John Doe\",\n",
    "        \"merge_FNAME\": \"John\",\n",
    "        \"merge_LNAME\": \"Doe\",\n",
    "        \"merge_PHONE\": \"1234567890\",\n",
    "        \"address_addr1\": \"123 Main St\",\n",
    "        \"address_addr2\": \"Apt 1\",\n",
    "        \"address_city\": \"Metropolis\",\n",
    "        \"address_state\": \"NY\",\n",
    "        \"address_zip\": \"12345\",\n",
    "        \"address_country\": \"USA\",\n",
    "        \"language\": \"en\",\n",
    "        \"vip\": False,\n",
    "        \"list_id\": \"list_1\",\n",
    "        \"list_name\": \"List One\",\n",
    "        \"location_country_code\": \"US\",\n",
    "        \"location_region\": \"NY\",\n",
    "        \"location_timezone\": \"EST\",\n",
    "        \"status\": \"subscribed\",\n",
    "        \"stats_avg_open_rate\": 0.5,\n",
    "        \"stats_avg_click_rate\": 0.2,\n",
    "        \"timestamp_signup\": \"2024-01-01T00:00:00Z\",\n",
    "        \"timestamp_opt\": \"2024-01-02T00:00:00Z\",\n",
    "        \"last_changed\": \"2024-01-03T00:00:00Z\",\n",
    "        \"member_rating\": 5,\n",
    "        \"consents_to_one_to_one_messaging\": True,\n",
    "        \"email_client\": \"Outlook\",\n",
    "        \"email_type\": \"html\",\n",
    "        \"web_id\": 111\n",
    "    },\n",
    "    {\n",
    "        \"unique_email_id\": \"uid_2\",\n",
    "        \"email_address\": \"jane.smith@example.com\",\n",
    "        \"full_name\": \"Jane Smith\",\n",
    "        \"merge_FNAME\": \"Jane\",\n",
    "        \"merge_LNAME\": \"Smith\",\n",
    "        \"merge_PHONE\": \"0987654321\",\n",
    "        \"address_addr1\": \"456 Elm St\",\n",
    "        \"address_addr2\": \"\",\n",
    "        \"address_city\": \"Gotham\",\n",
    "        \"address_state\": \"NJ\",\n",
    "        \"address_zip\": \"54321\",\n",
    "        \"address_country\": \"USA\",\n",
    "        \"language\": \"en\",\n",
    "        \"vip\": True,\n",
    "        \"list_id\": \"list_2\",\n",
    "        \"list_name\": \"List Two\",\n",
    "        \"location_country_code\": \"US\",\n",
    "        \"location_region\": \"NJ\",\n",
    "        \"location_timezone\": \"EST\",\n",
    "        \"status\": \"subscribed\",\n",
    "        \"stats_avg_open_rate\": 0.7,\n",
    "        \"stats_avg_click_rate\": 0.3,\n",
    "        \"timestamp_signup\": \"2024-02-01T00:00:00Z\",\n",
    "        \"timestamp_opt\": \"2024-02-02T00:00:00Z\",\n",
    "        \"last_changed\": \"2024-02-03T00:00:00Z\",\n",
    "        \"member_rating\": 3,\n",
    "        \"consents_to_one_to_one_messaging\": False,\n",
    "        \"email_client\": \"Gmail\",\n",
    "        \"email_type\": \"html\",\n",
    "        \"web_id\": 222\n",
    "    }\n",
    "]\n",
    "\n",
    "# Helper function to simulate spark.read.format(\"delta\").load(path)\n",
    "def fake_delta_load(path):\n",
    "    # Create a DataFrame from sample_data.\n",
    "    df = spark.createDataFrame(sample_data)\n",
    "    # Add the column \"list_name_source\" based on the directory name (last part of path)\n",
    "    list_name_source = os.path.basename(path)\n",
    "    return df.withColumn(\"list_name_source\", lit(list_name_source))\n",
    "\n",
    "class TestMailchimpGoldETL(unittest.TestCase):\n",
    "    \n",
    "    @patch(\"pyspark.sql.DataFrameWriter.save\")\n",
    "    def test_gold_etl(self, mock_save):\n",
    "        \"\"\"\n",
    "        Test the gold ETL logic:\n",
    "         - Union all delta files from silver layer.\n",
    "         - Create dim_contact, dim_list, and fact_list_membership tables.\n",
    "         - Write out using Delta mode (here we just verify that the write method is called).\n",
    "        \"\"\"\n",
    "        # Simulate dbutils.fs.ls output (already provided by our fake dbutils)\n",
    "        silver_base = \"abfss://silver@mailchimpspnetwork.dfs.core.windows.net/mailchimp_transformed\"\n",
    "        df_paths = dbutils.fs.ls(silver_base)\n",
    "        delta_paths = [f.path for f in df_paths if f.isDir]\n",
    "        \n",
    "        # Patch the spark.read.format(\"delta\").load to use our fake_delta_load\n",
    "        original_read = spark.read.format(\"delta\").load\n",
    "        try:\n",
    "            spark.read.format(\"delta\").load = fake_delta_load  # override with fake loader\n",
    "            all_data = None\n",
    "            for path in delta_paths:\n",
    "                df = spark.read.format(\"delta\").load(path)\n",
    "                # Add a column to identify the source list name using the directory name\n",
    "                df = df.withColumn(\"list_name_source\", lit(path.split(\"/\")[-1]))\n",
    "                all_data = df if all_data is None else all_data.unionByName(df)\n",
    "            \n",
    "            # Verify the union: we simulated 2 directories, so expect two copies of the sample_data\n",
    "            self.assertEqual(all_data.count(), len(sample_data) * len(delta_paths))\n",
    "            \n",
    "            # -------------------------------\n",
    "            # 1. Create the dimension table 'dim_contact'\n",
    "            # -------------------------------\n",
    "            dim_contact = all_data.select(\n",
    "                \"unique_email_id\",\n",
    "                \"email_address\",\n",
    "                \"full_name\",\n",
    "                \"merge_FNAME\",\n",
    "                \"merge_LNAME\",\n",
    "                \"merge_PHONE\",\n",
    "                \"address_addr1\",\n",
    "                \"address_addr2\",\n",
    "                \"address_city\",\n",
    "                \"address_state\",\n",
    "                \"address_zip\",\n",
    "                \"address_country\",\n",
    "                \"language\",\n",
    "                \"vip\"\n",
    "            ).dropDuplicates([\"unique_email_id\"])\n",
    "            \n",
    "            # For sample_data, there are two unique email ids.\n",
    "            self.assertEqual(dim_contact.count(), 2)\n",
    "            \n",
    "            # Instead of actually writing out, we simulate the write call by calling .write\n",
    "            # (The patch on DataFrameWriter.save ensures that save() is called)\n",
    "            GOLD_BASE = \"abfss://gold@mailchimpspnetwork.dfs.core.windows.net\"\n",
    "            dim_contact.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/dim_contact\")\n",
    "            mock_save.assert_called()  # Ensure write.save() was called\n",
    "            \n",
    "            # -------------------------------\n",
    "            # 2. Create the dimension table 'dim_list'\n",
    "            # -------------------------------\n",
    "            dim_list = all_data.select(\n",
    "                \"list_id\",\n",
    "                \"list_name\",\n",
    "                \"location_country_code\",\n",
    "                \"location_region\",\n",
    "                \"location_timezone\"\n",
    "            ).dropDuplicates([\"list_id\"])\n",
    "            # There are two unique list_ids in our sample data.\n",
    "            self.assertEqual(dim_list.count(), 2)\n",
    "            \n",
    "            dim_list.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/dim_list\")\n",
    "            self.assertTrue(mock_save.call_count >= 2)\n",
    "            \n",
    "            # -------------------------------\n",
    "            # 3. Create the fact table 'fact_list_membership'\n",
    "            # -------------------------------\n",
    "            fact_membership = all_data.select(\n",
    "                \"unique_email_id\",\n",
    "                \"list_id\",\n",
    "                \"status\",\n",
    "                \"stats_avg_open_rate\",\n",
    "                \"stats_avg_click_rate\",\n",
    "                \"timestamp_signup\",\n",
    "                \"timestamp_opt\",\n",
    "                \"last_changed\",\n",
    "                \"member_rating\",\n",
    "                \"consents_to_one_to_one_messaging\",\n",
    "                \"email_client\",\n",
    "                \"email_type\",\n",
    "                \"web_id\"\n",
    "            ).dropDuplicates([\"unique_email_id\", \"list_id\"])\n",
    "            # Since each record in our sample is unique, after union, the duplicates are removed based on the composite key.\n",
    "            # With two copies per record, the dropDuplicates should leave only the unique set.\n",
    "            self.assertEqual(fact_membership.count(), len(sample_data))\n",
    "            \n",
    "            fact_membership.write.format(\"delta\").mode(\"overwrite\").save(f\"{GOLD_BASE}/fact_list_membership\")\n",
    "            self.assertTrue(mock_save.call_count >= 3)\n",
    "        finally:\n",
    "            # Restore original method if needed\n",
    "            spark.read.format(\"delta\").load = original_read\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "003test_gold_etl_unit",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
